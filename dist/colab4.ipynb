{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6218f05f",
   "metadata": {},
   "source": [
    "# Learning on Dynamic Text-attributed Graphs\n",
    "\n",
    "While we haven't explicitly covered dynamics graphs in this course, we believe an exciting application is when the edges encode textual information about the entities represented by the nodes. \n",
    "\n",
    "In short, dynamic graphs are graphs where edges and nodes are created, updated, or removed over a duration of time. Time can either be continuous (fractions of a second, for instance) or discrete (ie, as integer time steps). \"Actions\" can occur along these discrete or continuous segments of time.\n",
    "\n",
    "In this notebook, we focus on a recent collection of such graphs called the **D**ynamic **T**ext-attributed **G**raph **B**enchmark ([DTGB](https://arxiv.org/abs/2406.12072)). \n",
    "\n",
    "> Specifically, we'll be using **GDELT**, a temporal knowledge graph dataset that tracks worldwide political behaviour. Nodes indicate entities like the *United States* or *Barack Obama*. It follows that edges represent relationships between these entities, capturing some type of political behaviour (eg: `Joe Biden <--Is President--> United States`). The edges are organized based on their datetime of occurrence. \n",
    "\n",
    "The dataset is originally from the [GDELT Project](https://www.gdeltproject.org/) that aims to capture real-time updates in the worldwide political landscape. \n",
    "\n",
    "### The task\n",
    "We focus on **(binary) link prediction**, ie, whether an edge should exist between two nodes. The graph is a dynamic knowledge graph where nodes are political entities and edges denote relationships between these entities. These node and edge features are in textual format which must be embedded (we use BERT). The model we're using is GraphMixer, a MLP-Mixer-based architecture that will operate on these node and edge text embeddings.\n",
    "\n",
    "We'll first transform our textual attributes into embeddings, followed by building our data loader, and finally, constructing the model architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce887da1-9a78-4439-a52c-2d04d76d8488",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    "\n",
    "Run this cell to make the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26adf917-c83b-4c5b-9f18-001db72c95a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    if \"transformers\" in logger.name.lower():\n",
    "        logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab7926-8faf-4cbe-9c28-d9ef38ea1950",
   "metadata": {},
   "source": [
    "## 1. Downloading GDELT\n",
    "\n",
    "The GDELT dataset has been hosted on [Google Drive](https://drive.google.com/drive/folders/1QFxHIjusLOFma30gF59_hcB19Ix3QZtk). Please download and unzip the `GDELT.zip` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff051c3-674f-43d4-96a7-bac609a5df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = './GDELT/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18932dcd-97c1-4a2f-b737-e5d31d395bdc",
   "metadata": {},
   "source": [
    "## 2. Feature extraction using BERT\n",
    "\n",
    "The nodes and edges are in text format. To encode these pieces of text, we'll be using [BERT](https://arxiv.org/abs/1810.04805), a popular text encoder model built with the Transformer architecture covered in class.\n",
    "\n",
    "We'll be using HuggingFace's [`transformers`](https://github.com/huggingface/transformers) library that provides wrappers around popular Transformer models, with BERT being one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ed757-360c-45db-af37-d29b7de8f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6eee31",
   "metadata": {},
   "source": [
    "Here, we'll be using the `bert-base-uncased` model. It means we're using the base model (with the smallest parameter count) that doesn't factor in the case (upper or lower) of the text passed in. This takes in input text and converts it into an embedding of some dimension $d=768$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8488b7-889a-4f61-b7cf-104eeb274374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare the BERT model and tokenizer\n",
    "config = AutoConfig.from_pretrained('bert-base-uncased')\n",
    "hidden_size = config.hidden_size # 768\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "BERT_model = AutoModel.from_pretrained('bert-base-uncased').cuda()\n",
    "\n",
    "# NOTE: remove the .cuda() if you wish to run this on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87ff16",
   "metadata": {},
   "source": [
    "Here's a short demo on using the tokenizer and language model to encode text into embeddings. You'll be using a similar strategy later on to embed the node and edge attributes! \n",
    "\n",
    "> You can ignore the parameters passed into the functions – keep them the same when you're using them on the graph data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8736ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "texts = [\n",
    "    \"you've heard of cat on the mat – what about giraffe on the graph?\", \n",
    "    \"what a wonderful day to learn on graphs!\", \n",
    "    \"this is a very long, uninformative, run-on sentence with no punchline!\"\n",
    "]\n",
    "\n",
    "# tokenize the text (ie, convert text -> numbers)\n",
    "tokens = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad(): # we do not want gradients to flow\n",
    "    out = BERT_model(**tokens)[1] # the items in the [1] index contain the text embeddings of interest\n",
    "    print (out.shape)\n",
    "    \n",
    "# note how the first dimension of the output is the # of sentences in the `texts` list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec4f03-5abb-4fa4-958a-48d7683766b2",
   "metadata": {},
   "source": [
    "## 3. Encoding text attributes along nodes and edges\n",
    "\n",
    "Now, let's use BERT in a similar way to encode the text attributes in the graph. Remember, the edges capture political relationships or behaviour between entities. \n",
    "\n",
    "> **NOTE**: Remember, when you're running the forward pass through the BERT model, we do _NOT_ want gradients to flow, so remember to use `torch.no_grad()` carefully.\n",
    "\n",
    "The GDELT dataset contains a few files in CSV format. Each record contains a tuple representing either a node or edge, which when put together forms the entire (temporal) knowledge graph. Here's a succinct description of each column in the CSV files:\n",
    "- **edge_list.csv**: \n",
    "    - `u`: ID of the source entity\n",
    "    - `i`: ID of the target/recipient entity\n",
    "    - `r`: ID of the relation between them\n",
    "    - `ts`: the timestamp at which the edge occurs\n",
    "    - `l`: the label of the edge\n",
    "- **entity_text.csv**:\n",
    "    - `i`: ID of the entity\n",
    "    - `text`: text description of entity (eg: \"obama\", \"egypt\", \"romanian\")\n",
    "- **relation_text.csv*: \n",
    "    - `i`: ID of the relation edge (as listed in edge_list.csv)\n",
    "    - `text`: text content of the relationship (eg: \"makes a visit\", \"engage in negotiation\")\n",
    "    \n",
    "The first column is usually the _index_ of the record, which is just for enumeration. You can ignore this, we don't access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d878c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = pd.read_csv(os.path.join(dataset_root, 'edge_list.csv'))\n",
    "num_node = max(edge_list['u'].max(), edge_list['i'].max())\n",
    "num_rel = edge_list['r'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b8642",
   "metadata": {},
   "source": [
    "### Question 1 (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e666b5-798c-4344-8eaa-931f24f6fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the node text attributes\n",
    "entity_embeddings = [np.zeros([1, hidden_size])]\n",
    "entity_text_reader = pd.read_csv(os.path.join(dataset_root, 'entity_text.csv'), chunksize=1000)\n",
    "\n",
    "for batch in entity_text_reader:\n",
    "    id_batch = batch['i'].tolist()\n",
    "    text_batch = batch['text'].tolist()\n",
    "    if 0 in id_batch:  # ignore the first row\n",
    "        id_batch = id_batch[1:]\n",
    "        text_batch = text_batch[1:] # you need to pass this `list` into the tokenizer + BERT pipeline\n",
    "    \n",
    "    ## Question 1: Embed the text attributes from the entity nodes\n",
    "    ############# Your code here ############\n",
    "    ## (~4-5 lines of code)\n",
    "    \n",
    "    # A. tokenize the text and push it to the CUDA device\n",
    "    \n",
    "    # B. put it through the BERT model (`BERT_model`) and extract the tensors from the output at the [1] index\n",
    "    \n",
    "    # C. put the output tensors on CPU\n",
    "    \n",
    "    # D. remember to add the output (in numpy format) of the current batch into the `entity_embeddings` np.array\n",
    "        \n",
    "    #########################################\n",
    "            \n",
    "# concatenate the outputs from each batch into one large tensor\n",
    "entity_embeddings = np.concatenate(entity_embeddings, axis=0)\n",
    "print([entity_embeddings.shape, num_node])\n",
    "assert len(entity_embeddings) == num_node + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08eb5f",
   "metadata": {},
   "source": [
    "### Question 2 (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1a8c8-d43a-4795-b440-f706efdfa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_embeddings = []\n",
    "rel_text_reader = pd.read_csv(os.path.join(dataset_root, 'relation_text.csv'), chunksize=1000)\n",
    "\n",
    "# embed the edge text attributes\n",
    "for batch in rel_text_reader:\n",
    "    id_batch = batch['i'].tolist()\n",
    "    text_batch = batch['text'].tolist()\n",
    "    if 0 in id_batch:  # ignore the first row\n",
    "        id_batch = id_batch[1:]\n",
    "        text_batch = text_batch[1:] # you need to pass this `list` into the tokenizer + BERT pipeline\n",
    "        \n",
    "    ## Question 2: Embed the text attributes from the relationships\n",
    "    ############# Your code here ############\n",
    "    ## (~4-5 lines of code)\n",
    "    \n",
    "    # A. tokenize the text and push it to the CUDA device\n",
    "    \n",
    "    # B. put it through the BERT model (`BERT_model`) and extract the tensors from the output at the [1] index\n",
    "    \n",
    "    # C. put the output tensors on CPU\n",
    "    \n",
    "    # D. remember to add the output (in numpy format) of the current batch into the `rel_embeddings` np.array\n",
    "        \n",
    "    #########################################\n",
    "\n",
    "rel_embeddings = np.concatenate(rel_embeddings, axis=0)\n",
    "assert len(rel_embeddings) == num_rel\n",
    "print(rel_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba39b9-565e-4934-a72f-b828e5ac23a6",
   "metadata": {},
   "source": [
    "## 4. Creating a dataset\n",
    "\n",
    "To convert this disparate encoded data into a machine-learnable format, we'll be wrapping it in a `Data` object for easier access downstream. Each `Data` instance contains a single relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71690d04-8cd0-49fc-9a50-ca5d5d72c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(\n",
    "            self, \n",
    "            src_node_ids: np.ndarray, \n",
    "            dst_node_ids: np.ndarray, \n",
    "            node_interact_times: np.ndarray, \n",
    "            edge_ids: np.ndarray, \n",
    "            labels: np.ndarray\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Data object to store the nodes interaction information.\n",
    "        \n",
    "        :param src_node_ids: ndarray\n",
    "        :param dst_node_ids: ndarray\n",
    "        :param node_interact_times: ndarray\n",
    "        :param edge_ids: ndarray\n",
    "        :param labels: ndarray\n",
    "        \"\"\"\n",
    "        self.src_node_ids = src_node_ids\n",
    "        self.dst_node_ids = dst_node_ids\n",
    "        self.node_interact_times = node_interact_times\n",
    "        self.edge_ids = edge_ids\n",
    "        self.labels = labels\n",
    "        self.num_interactions = len(src_node_ids)\n",
    "        self.unique_node_ids = set(src_node_ids) | set(dst_node_ids)\n",
    "        self.num_unique_nodes = len(self.unique_node_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33917771",
   "metadata": {},
   "source": [
    "Here, we simply package the data we've embedded into a nice machine-learnable format for an edge classification setting.\n",
    "\n",
    "Implement the code to create the test data using the training and validation data as a template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f9c72",
   "metadata": {},
   "source": [
    "### Question 3 (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3c245-664f-4416-8178-8cdf0c81fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2020)\n",
    "\n",
    "def get_edge_classification_data(dataset_name: str, val_ratio: float, test_ratio: float):\n",
    "    \"\"\"\n",
    "    generate data for link prediction task (inductive & transductive settings)\n",
    "    \n",
    "    :param dataset_name: str, dataset name\n",
    "    :param val_ratio: float, validation data ratio\n",
    "    :param test_ratio: float, test data ratio\n",
    "    :return: node_raw_features, edge_raw_features, (np.ndarray),\n",
    "            full_data, train_data, val_data, test_data, new_node_val_data, new_node_test_data, (Data object)\n",
    "    \"\"\"\n",
    "    # Load data and train val test split\n",
    "    graph_df = pd.read_csv(os.path.join(dataset_root, 'edge_list.csv'))\n",
    "    node_num = max(graph_df['u'].max(), graph_df['i'].max()) + 1\n",
    "\n",
    "    graph_df.ts = graph_df.ts // 15  # timestamp\n",
    "    cat_num = graph_df['label'].max() + 1\n",
    "    rel_num = cat_num\n",
    "\n",
    "    src_node_ids = graph_df.u.values.astype(np.longlong)\n",
    "    dst_node_ids = graph_df.i.values.astype(np.longlong)\n",
    "    node_interact_times = graph_df.ts.values.astype(np.float64)\n",
    "    edge_ids = graph_df.label.values.astype(np.longlong) #graph_df.r.values.astype(np.longlong)\n",
    "    labels = graph_df.label.values\n",
    "\n",
    "    full_data = Data(\n",
    "                    src_node_ids=src_node_ids, \n",
    "                    dst_node_ids=dst_node_ids, \n",
    "                    node_interact_times=node_interact_times, \n",
    "                    edge_ids=edge_ids, \n",
    "                    labels=labels\n",
    "                )\n",
    "\n",
    "    # get the timestamp of validate and test set\n",
    "    val_time, test_time = list(np.quantile(graph_df.ts, [(1 - val_ratio - test_ratio), (1 - test_ratio)]))\n",
    "    \n",
    "    # union to get node set\n",
    "    node_set = set(src_node_ids) | set(dst_node_ids)\n",
    "    num_total_unique_node_ids = len(node_set)\n",
    "\n",
    "    # compute nodes which appear at test time\n",
    "    test_node_set = set(src_node_ids[node_interact_times > val_time]).union(set(dst_node_ids[node_interact_times > val_time]))\n",
    "    # sample nodes which we keep as new nodes (to test inductiveness), so then we have to remove all their edges from training\n",
    "    new_test_node_sample_size = min(len(test_node_set), int(0.1 * num_total_unique_node_ids))\n",
    "    new_test_node_set = set(random.sample(list(test_node_set), new_test_node_sample_size))\n",
    "\n",
    "    # mask for each source and destination to denote whether they are new test nodes\n",
    "    new_test_source_mask = graph_df.u.map(lambda x: x in new_test_node_set).values\n",
    "    new_test_destination_mask = graph_df.i.map(lambda x: x in new_test_node_set).values\n",
    "\n",
    "    # mask, which is true for edges with both destination and source not being new test nodes (because we want to remove all edges involving any new test node)\n",
    "    observed_edges_mask = np.logical_and(~new_test_source_mask, ~new_test_destination_mask)\n",
    "\n",
    "    # for train data, we keep edges happening before the validation time which do not involve any new node, used for inductiveness\n",
    "    train_mask = np.logical_and(node_interact_times <= val_time, observed_edges_mask)\n",
    "\n",
    "    train_data = Data(\n",
    "                    src_node_ids=src_node_ids[train_mask], \n",
    "                    dst_node_ids=dst_node_ids[train_mask],\n",
    "                    node_interact_times=node_interact_times[train_mask],\n",
    "                    edge_ids=edge_ids[train_mask], \n",
    "                    labels=labels[train_mask]\n",
    "                )\n",
    "\n",
    "    # define the new nodes sets for testing inductiveness of the model\n",
    "    train_node_set = set(train_data.src_node_ids).union(train_data.dst_node_ids)\n",
    "    assert len(train_node_set & new_test_node_set) == 0\n",
    "\n",
    "    val_mask = np.logical_and(node_interact_times <= test_time, node_interact_times > val_time)\n",
    "    test_mask = node_interact_times > test_time\n",
    "\n",
    "    ## Question 3: Create the test and validation data in a similar way as the training set using the masks\n",
    "    ############# Your code here ############\n",
    "    ## (~2 lines of code)\n",
    "    \n",
    "    val_data = None\n",
    "    \n",
    "    test_data = None\n",
    "        \n",
    "    #########################################    \n",
    "\n",
    "    # output some graph statistics\n",
    "    print(\"The dataset has {} interactions, involving {} different nodes\".format(\n",
    "        full_data.num_interactions, full_data.num_unique_nodes))\n",
    "    print(\"The training dataset has {} interactions, involving {} different nodes\".format(\n",
    "        train_data.num_interactions, train_data.num_unique_nodes))\n",
    "    print(\"The validation dataset has {} interactions, involving {} different nodes\".format(\n",
    "        val_data.num_interactions, val_data.num_unique_nodes))\n",
    "    print(\"The test dataset has {} interactions, involving {} different nodes\".format(\n",
    "        test_data.num_interactions, test_data.num_unique_nodes))\n",
    "\n",
    "    return full_data, train_data, val_data, test_data, cat_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c9368-6892-46ce-85cf-ea76ecc0aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data splits\n",
    "full_data, train_data, val_data, test_data, cat_num = get_edge_classification_data(\"GDELT\", 0.15, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24088ae",
   "metadata": {},
   "source": [
    "Here, we create a wrapper that stores the indices of the nodes within each split, this makes access easier in the dataloader.\n",
    "\n",
    "> You don't need to understand this code, feel free to run it and move on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39053a0-281d-40e3-b754-1fd7b1523966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomizedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, indices_list: list):\n",
    "        \"\"\"\n",
    "        Customized dataset.\n",
    "        \n",
    "        :param indices_list: list, list of indices\n",
    "        \"\"\"\n",
    "        super(CustomizedDataset, self).__init__()\n",
    "\n",
    "        self.indices_list = indices_list\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        get item at the index in self.indices_list\n",
    "        \n",
    "        :param idx: int, the index\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.indices_list[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices_list)\n",
    "\n",
    "\n",
    "def get_idx_data_loader(indices_list: list, batch_size: int, shuffle: bool):\n",
    "    \"\"\"\n",
    "    get data loader that iterates over indices\n",
    "    \n",
    "    :param indices_list: list, list of indices\n",
    "    :param batch_size: int, batch size\n",
    "    :param shuffle: boolean, whether to shuffle the data\n",
    "    :return: data_loader, DataLoader\n",
    "    \"\"\"\n",
    "    dataset = CustomizedDataset(indices_list=indices_list)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             drop_last=False,\n",
    "                             num_workers=2)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1bcc0-7635-4d77-a08b-786fd94735ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "\n",
    "train_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(train_data.src_node_ids))), batch_size=128, shuffle=False)\n",
    "val_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(val_data.src_node_ids))), batch_size=128, shuffle=False)\n",
    "test_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(test_data.src_node_ids))), batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba59607-8817-4aca-ad7e-e9eef18ba9e6",
   "metadata": {},
   "source": [
    "## 5. Creating the NeighborSampler\n",
    "\n",
    "Since the graph is very large and dense, training a GNN on it would be very compute intensive. Instead, we can  smaller fragments/subgraphs of the graph to make training more sustainable.\n",
    "\n",
    "> You do not need to understand this part of the code, just run it before moving on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c1d458-65ed-4172-b5d8-87f80c02faf3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class NeighborSampler:\n",
    "    def __init__(self, adj_list: list, seed: int = None):\n",
    "        \"\"\"\n",
    "        Neighbor sampler.\n",
    "        \n",
    "        :param adj_list: list, list of list, where each element is a list of triple tuple (node_id, edge_id, timestamp)\n",
    "        :param seed: int, random seed\n",
    "        \"\"\"\n",
    "        self.seed = seed\n",
    "\n",
    "        # list of each node's neighbor ids, edge ids and interaction times, which are sorted by interaction times\n",
    "        self.nodes_neighbor_ids = []\n",
    "        self.nodes_edge_ids = []\n",
    "        self.nodes_neighbor_times = []\n",
    "\n",
    "        # the list at the first position in adj_list is empty, hence, sorted() will return an empty list for the first position\n",
    "        # its corresponding value in self.nodes_neighbor_ids, self.nodes_edge_ids, self.nodes_neighbor_times will also be empty with length 0\n",
    "        for node_idx, per_node_neighbors in enumerate(adj_list):\n",
    "            # per_node_neighbors is a list of tuples (neighbor_id, edge_id, timestamp)\n",
    "            # sort the list based on timestamps, sorted() function is stable\n",
    "            # Note that sort the list based on edge id is also correct, as the original data file ensures the interactions are chronological\n",
    "            sorted_per_node_neighbors = sorted(per_node_neighbors, key=lambda x: x[2])\n",
    "            self.nodes_neighbor_ids.append(np.array([x[0] for x in sorted_per_node_neighbors]))\n",
    "            self.nodes_edge_ids.append(np.array([x[1] for x in sorted_per_node_neighbors]))\n",
    "            self.nodes_neighbor_times.append(np.array([x[2] for x in sorted_per_node_neighbors]))\n",
    "\n",
    "        if self.seed is not None:\n",
    "            self.random_state = np.random.RandomState(self.seed)\n",
    "\n",
    "    def find_neighbors_before(self, node_id: int, interact_time: float):\n",
    "        \"\"\"\n",
    "        extracts all the interactions happening before interact_time (less than interact_time) for node_id in the overall interaction graph\n",
    "        the returned interactions are sorted by time.\n",
    "        \n",
    "        :param node_id: int, node id\n",
    "        :param interact_time: float, interaction time\n",
    "        :param return_sampled_probabilities: boolean, whether return the sampled probabilities of neighbors\n",
    "        :return: neighbors, edge_ids, timestamps and sampled_probabilities (if return_sampled_probabilities is True) with shape (historical_nodes_num, )\n",
    "        \"\"\"\n",
    "        # return index i, which satisfies list[i - 1] < v <= list[i]\n",
    "        # return 0 for the first position in self.nodes_neighbor_times since the value at the first position is empty\n",
    "        i = np.searchsorted(self.nodes_neighbor_times[node_id], interact_time)\n",
    "        return self.nodes_neighbor_ids[node_id][:i], self.nodes_edge_ids[node_id][:i], self.nodes_neighbor_times[node_id][:i]\n",
    "\n",
    "    def get_historical_neighbors(self, node_ids: np.ndarray, node_interact_times: np.ndarray, num_neighbors: int = 20):\n",
    "        \"\"\"\n",
    "        get historical neighbors of nodes in node_ids with interactions before the corresponding time in node_interact_times\n",
    "        \n",
    "        :param node_ids: ndarray, shape (batch_size, ) or (*, ), node ids\n",
    "        :param node_interact_times: ndarray, shape (batch_size, ) or (*, ), node interaction times\n",
    "        :param num_neighbors: int, number of neighbors to sample for each node\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert num_neighbors > 0, 'Number of sampled neighbors for each node should be greater than 0!'\n",
    "        # All interactions described in the following three matrices are sorted in each row by time\n",
    "        # each entry in position (i,j) represents the id of the j-th dst node of src node node_ids[i] with an interaction before node_interact_times[i]\n",
    "        # ndarray, shape (batch_size, num_neighbors)\n",
    "        nodes_neighbor_ids = np.zeros((len(node_ids), num_neighbors)).astype(np.longlong)\n",
    "        # each entry in position (i,j) represents the id of the edge with src node node_ids[i] and dst node nodes_neighbor_ids[i][j] with an interaction before node_interact_times[i]\n",
    "        # ndarray, shape (batch_size, num_neighbors)\n",
    "        nodes_edge_ids = np.zeros((len(node_ids), num_neighbors)).astype(np.longlong)\n",
    "        # each entry in position (i,j) represents the interaction time between src node node_ids[i] and dst node nodes_neighbor_ids[i][j], before node_interact_times[i]\n",
    "        # ndarray, shape (batch_size, num_neighbors)\n",
    "        nodes_neighbor_times = np.zeros((len(node_ids), num_neighbors)).astype(np.float32)\n",
    "\n",
    "        # extracts all neighbors ids, edge ids and interaction times of nodes in node_ids, which happened before the corresponding time in node_interact_times\n",
    "        for idx, (node_id, node_interact_time) in enumerate(zip(node_ids, node_interact_times)):\n",
    "            # find neighbors that interacted with node_id before time node_interact_time\n",
    "            node_neighbor_ids, node_edge_ids, node_neighbor_times = \\\n",
    "                self.find_neighbors_before(node_id=node_id, interact_time=node_interact_time)\n",
    "\n",
    "            if len(node_neighbor_ids) > 0:\n",
    "                # Take most recent interactions with number num_neighbors\n",
    "                node_neighbor_ids = node_neighbor_ids[-num_neighbors:]\n",
    "                node_edge_ids = node_edge_ids[-num_neighbors:]\n",
    "                node_neighbor_times = node_neighbor_times[-num_neighbors:]\n",
    "                # put the neighbors' information at the back positions\n",
    "                nodes_neighbor_ids[idx, num_neighbors - len(node_neighbor_ids):] = node_neighbor_ids\n",
    "                nodes_edge_ids[idx, num_neighbors - len(node_edge_ids):] = node_edge_ids\n",
    "                nodes_neighbor_times[idx, num_neighbors - len(node_neighbor_times):] = node_neighbor_times\n",
    "\n",
    "        # three ndarrays, with shape (batch_size, num_neighbors)\n",
    "        return nodes_neighbor_ids, nodes_edge_ids, nodes_neighbor_times\n",
    "\n",
    "    def get_multi_hop_neighbors(self, num_hops: int, node_ids: np.ndarray, node_interact_times: np.ndarray, num_neighbors: int = 20):\n",
    "        \"\"\"\n",
    "        get historical neighbors of nodes in node_ids within num_hops hops\n",
    "        \n",
    "        :param num_hops: int, number of sampled hops\n",
    "        :param node_ids: ndarray, shape (batch_size, ), node ids\n",
    "        :param node_interact_times: ndarray, shape (batch_size, ), node interaction times\n",
    "        :param num_neighbors: int, number of neighbors to sample for each node\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert num_hops > 0, 'Number of sampled hops should be greater than 0!'\n",
    "\n",
    "        # get the temporal neighbors at the first hop\n",
    "        # nodes_neighbor_ids, nodes_edge_ids, nodes_neighbor_times -> ndarray, shape (batch_size, num_neighbors)\n",
    "        nodes_neighbor_ids, nodes_edge_ids, nodes_neighbor_times = self.get_historical_neighbors(node_ids=node_ids,\n",
    "                                                                                                 node_interact_times=node_interact_times,\n",
    "                                                                                                 num_neighbors=num_neighbors)\n",
    "        # three lists to store the neighbor ids, edge ids and interaction timestamp information\n",
    "        nodes_neighbor_ids_list = [nodes_neighbor_ids]\n",
    "        nodes_edge_ids_list = [nodes_edge_ids]\n",
    "        nodes_neighbor_times_list = [nodes_neighbor_times]\n",
    "        for hop in range(1, num_hops):\n",
    "            # get information of neighbors sampled at the current hop\n",
    "            # three ndarrays, with shape (batch_size * num_neighbors ** hop, num_neighbors)\n",
    "            nodes_neighbor_ids, nodes_edge_ids, nodes_neighbor_times = self.get_historical_neighbors(node_ids=nodes_neighbor_ids_list[-1].flatten(),\n",
    "                                                                                                     node_interact_times=nodes_neighbor_times_list[-1].flatten(),\n",
    "                                                                                                     num_neighbors=num_neighbors)\n",
    "            # three ndarrays with shape (batch_size, num_neighbors ** (hop + 1))\n",
    "            nodes_neighbor_ids = nodes_neighbor_ids.reshape(len(node_ids), -1)\n",
    "            nodes_edge_ids = nodes_edge_ids.reshape(len(node_ids), -1)\n",
    "            nodes_neighbor_times = nodes_neighbor_times.reshape(len(node_ids), -1)\n",
    "\n",
    "            nodes_neighbor_ids_list.append(nodes_neighbor_ids)\n",
    "            nodes_edge_ids_list.append(nodes_edge_ids)\n",
    "            nodes_neighbor_times_list.append(nodes_neighbor_times)\n",
    "\n",
    "        # tuple, each element in the tuple is a list of num_hops ndarrays, each with shape (batch_size, num_neighbors ** current_hop)\n",
    "        return nodes_neighbor_ids_list, nodes_edge_ids_list, nodes_neighbor_times_list\n",
    "\n",
    "    def get_all_first_hop_neighbors(self, node_ids: np.ndarray, node_interact_times: np.ndarray):\n",
    "        \"\"\"\n",
    "        get historical neighbors of nodes in node_ids at the first hop with max_num_neighbors as the maximal number of neighbors (make the computation feasible)\n",
    "\n",
    "        :param node_ids: ndarray, shape (batch_size, ), node ids\n",
    "        :param node_interact_times: ndarray, shape (batch_size, ), node interaction times\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # three lists to store the first-hop neighbor ids, edge ids and interaction timestamp information, with batch_size as the list length\n",
    "        nodes_neighbor_ids_list, nodes_edge_ids_list, nodes_neighbor_times_list = [], [], []\n",
    "        # get the temporal neighbors at the first hop\n",
    "        for idx, (node_id, node_interact_time) in enumerate(zip(node_ids, node_interact_times)):\n",
    "            # find neighbors that interacted with node_id before time node_interact_time\n",
    "            node_neighbor_ids, node_edge_ids, node_neighbor_times, _ = self.find_neighbors_before(node_id=node_id,\n",
    "                                                                                                  interact_time=node_interact_time,\n",
    "                                                                                                  return_sampled_probabilities=False)\n",
    "            nodes_neighbor_ids_list.append(node_neighbor_ids)\n",
    "            nodes_edge_ids_list.append(node_edge_ids)\n",
    "            nodes_neighbor_times_list.append(node_neighbor_times)\n",
    "\n",
    "        return nodes_neighbor_ids_list, nodes_edge_ids_list, nodes_neighbor_times_list\n",
    "\n",
    "    def reset_random_state(self):\n",
    "        \"\"\"\n",
    "        reset the random state by self.seed\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.random_state = np.random.RandomState(self.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff3551b",
   "metadata": {},
   "source": [
    "### Question 4 (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_sampler(data: Data, seed: int = None):\n",
    "    \"\"\"\n",
    "    get neighbor sampler for the large knowledge graph\n",
    "    \n",
    "    :param data: Data\n",
    "    :param seed: int, random seed\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_node_id = max(data.src_node_ids.max(), data.dst_node_ids.max())\n",
    "    # the adjacency vector stores edges for each node (source or destination), undirected\n",
    "    # adj_list, list of list, where each element is a list of triple tuple (node_id, edge_id, timestamp)\n",
    "    # the list at the first position in adj_list is empty\n",
    "\n",
    "    adj_list = [[] for _ in range(max_node_id + 1)]\n",
    "    \n",
    "    # iterate through the graph's edges\n",
    "    for src_node_id, dst_node_id, edge_id, node_interact_time in zip(data.src_node_ids, data.dst_node_ids, data.edge_ids, data.node_interact_times):\n",
    "        \n",
    "        ## Question 4: Create the UNDIRECTED adjacency list by appending each node's neighbors and \n",
    "        ##             its related information based on the description of adj_list's contents above.\n",
    "        ############# Your code here ############\n",
    "        ## (~2 lines of code)\n",
    "        \n",
    "        \n",
    "\n",
    "        #########################################    \n",
    "        \n",
    "\n",
    "    return NeighborSampler(adj_list=adj_list, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3fccec-c0d0-4843-b4f5-01f71cee2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_neighbor_sampler = get_neighbor_sampler(data=full_data, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e11262-fa5b-4041-be1f-91f252efe4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training neighbor sampler to retrieve temporal graph\n",
    "train_neighbor_sampler = get_neighbor_sampler(data=train_data, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda2c0c-0372-4d32-9b49-f09c3f149239",
   "metadata": {},
   "source": [
    "## 6. Model implementation\n",
    "\n",
    "Now that we've finished encoding the text attributes in the graph dataset, we can finally start building the main GNN that learns on this dynamic encoded knowledge graph. .\n",
    "\n",
    "Our model of choice to learn on the knowledge graph is [GraphMixer](https://arxiv.org/abs/2302.11636). It's a powerful architecture that tries to substitute expensive self-attention operations in vision-transformer-like models using MLP-like modules within. We'll build a mechanism to encode the timestamps these events occur at, as well as a binary edge classifier to make the final link prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7cf80a",
   "metadata": {},
   "source": [
    "### 6A: Building the TimeEncoder and Edge Classifier (Question 5-6: 20 points)\n",
    "\n",
    "Let's first get started with the time encoder and binary edge classifier. The time encoder takes in the timestamp and outputs an embedding vector representing it. While the edge classifier is a straightforward MLP that takes in edge features after message passing, the time encoder is initialized in a certain way. For an event timestamp `t`, we have a **fixed** weight $\\mathbf{\\omega}$ that embeds the timestamp into different frequencies along the vector's dimensions to .\n",
    "\n",
    "$$\n",
    "\\mathbf{\\omega} = \\{\\alpha^{-(i-1)/\\beta}\\}^{d}_{i=1} \\in [0, t) \\\\\n",
    "\\mathbf{p} = \\cos{(t\\mathbf{\\omega})} \\in [-1, +1]\n",
    "$$\n",
    "\n",
    "Specifically,\n",
    "$$\n",
    "\\mathbf{p} = \\begin{bmatrix}\n",
    "    \\cos{(t \\cdot \\alpha^{-0/\\beta})} \\\\\n",
    "    \\cos{(t \\cdot \\alpha^{-1/\\beta})} \\\\\n",
    "    \\cos{(t \\cdot \\alpha^{-2/\\beta})} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\cos{(t \\cdot \\alpha^{-(d-1)/\\beta})} \\\\\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{d}\n",
    "$$\n",
    "\n",
    "Here, $\\alpha$ and $\\beta$ correspond to hyperparameters based on the maximum timestamp we're encoding $t_{\\text{max}}$ (we've already set these for you). Here, we set $d=100$ (it's called `time_dim` below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b577b0-b56d-4f6a-8d70-3130628f08db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TimeEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, time_dim: int, parameter_requires_grad: bool = True):\n",
    "        \"\"\"\n",
    "        Time encoder.\n",
    "        \n",
    "        :param time_dim: int, dimension of time encodings\n",
    "        :param parameter_requires_grad: boolean, whether the parameter in TimeEncoder needs gradient\n",
    "        \"\"\"\n",
    "        super(TimeEncoder, self).__init__()\n",
    "\n",
    "        self.time_dim = time_dim\n",
    "        # trainable parameters for time encoding\n",
    "        self.w = nn.Linear(1, time_dim)\n",
    "        self.w.weight = nn.Parameter((torch.from_numpy(1 / 10 ** np.linspace(0, 9, time_dim, dtype=np.float32))).reshape(time_dim, -1))\n",
    "        self.w.bias = nn.Parameter(torch.zeros(time_dim))\n",
    "\n",
    "        if not parameter_requires_grad:\n",
    "            self.w.weight.requires_grad = False\n",
    "            self.w.bias.requires_grad = False\n",
    "\n",
    "    def forward(self, timestamps: torch.Tensor):\n",
    "        \"\"\"\n",
    "        compute time encodings of time in timestamps\n",
    "        \n",
    "        :param timestamps: Tensor, shape (batch_size, seq_len)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        ## Question 5: Encode the timestamps using the linear layer with pre-initialized weights\n",
    "        ############# Your code here ############\n",
    "        ## (~2 lines of code)\n",
    "        \n",
    "        # reshape the `timestamps` tensor to be of shape (batch_size, seq_len, 1)\n",
    "        \n",
    "        # project this output using layer `w` and pass it through a cosine – call it `output`\n",
    "        \n",
    "        #########################################\n",
    "\n",
    "        return output # Tensor of shape (batch_size, seq_len, time_dim)\n",
    "\n",
    "class MLPClassifier_edge(nn.Module):\n",
    "    def __init__(self, input_dim: int, dropout: float = 0.1, cat_num: int = 0):\n",
    "        \"\"\"\n",
    "        Multi-Layer Perceptron Classifier.\n",
    "        \n",
    "        :param input_dim: int, dimension of input\n",
    "        :param dropout: float, dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2*input_dim, input_dim, bias = True)\n",
    "        self.fc2 = nn.Linear(input_dim, input_dim, bias = True)\n",
    "        self.fc3 = nn.Linear(input_dim, cat_num, bias = True)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout) # feel free to add this anywhere in your network (except the final layer)\n",
    "\n",
    "    def forward(self, x_1: torch.Tensor, x_2: torch.Tensor, rel_embs: torch.Tensor):\n",
    "        \"\"\"\n",
    "        multi-layer perceptron classifier forward process\n",
    "        \n",
    "        :param x: Tensor, shape (*, input_dim)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ## Question 6: Pass the concatenated node embeddings `x_1` and `x_2` through the MLP\n",
    "        ############# Your code here ############\n",
    "        ## (~3 lines of code)\n",
    "        \n",
    "        # NOTE: be sure to concatenate along the correct dimensions!\n",
    "        \n",
    "        #########################################\n",
    "        \n",
    "        return output # Tensor of shape (*, input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd91817",
   "metadata": {},
   "source": [
    "### 6B. Building GraphMixer\n",
    "\n",
    "GraphMixer has a few components described below:\n",
    "- **node encoder**: captures node embeddings by incorporating the entity and associated relationship\n",
    "- **edge/link encoder**: learns edge embeddings using channel and token mixing\n",
    "- **link classifier**: predicts whether an edge exists between two nodes at some time $t_0$. It takes in the outputs of the link encoder and node encoder and outputs a binary classification. We've already implemented `MLPClassifier_edge` above.\n",
    "\n",
    "We'll be building the entire model in a top-down fashion with the high-level GraphMixer first, followed by the miscellaneous modules used internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ccf1c-5a8e-4b1a-9caf-de25b33aef74",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class GraphMixer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            node_raw_features: np.ndarray, \n",
    "            edge_raw_features: np.ndarray, \n",
    "            neighbor_sampler: NeighborSampler,\n",
    "            time_feat_dim: int, \n",
    "            num_tokens: int, \n",
    "            num_layers: int = 2, \n",
    "            token_dim_expansion_factor: float = 0.5,\n",
    "            channel_dim_expansion_factor: float = 4.0, \n",
    "            dropout: float = 0.1, device: str = 'cpu'\n",
    "        ):\n",
    "        \"\"\"\n",
    "        TCL model.\n",
    "        \n",
    "        :param node_raw_features: ndarray, shape (num_nodes + 1, node_feat_dim)\n",
    "        :param edge_raw_features: ndarray, shape (num_edges + 1, edge_feat_dim)\n",
    "        :param neighbor_sampler: neighbor sampler\n",
    "        :param time_feat_dim: int, dimension of time features (encodings)\n",
    "        :param num_tokens: int, number of tokens\n",
    "        :param num_layers: int, number of transformer layers\n",
    "        :param token_dim_expansion_factor: float, dimension expansion factor for tokens\n",
    "        :param channel_dim_expansion_factor: float, dimension expansion factor for channels\n",
    "        :param dropout: float, dropout rate\n",
    "        :param device: str, device\n",
    "        \"\"\"\n",
    "        super(GraphMixer, self).__init__()\n",
    "\n",
    "        self.node_raw_features = torch.from_numpy(node_raw_features.astype(np.float32)).to(device)\n",
    "        self.edge_raw_features = torch.from_numpy(edge_raw_features.astype(np.float32)).to(device)\n",
    "\n",
    "        self.neighbor_sampler = neighbor_sampler\n",
    "        self.node_feat_dim = self.node_raw_features.shape[1]\n",
    "        self.edge_feat_dim = self.edge_raw_features.shape[1]\n",
    "        self.time_feat_dim = time_feat_dim\n",
    "        self.num_tokens = num_tokens\n",
    "        self.num_layers = num_layers\n",
    "        self.token_dim_expansion_factor = token_dim_expansion_factor\n",
    "        self.channel_dim_expansion_factor = channel_dim_expansion_factor\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "\n",
    "        self.num_channels = self.edge_feat_dim\n",
    "        # in GraphMixer, the time encoding function is not trainable\n",
    "        self.time_encoder = TimeEncoder(time_dim=time_feat_dim, parameter_requires_grad=False)\n",
    "        self.projection_layer = nn.Linear(self.edge_feat_dim + time_feat_dim, self.num_channels)\n",
    "\n",
    "        self.mlp_mixers = nn.ModuleList([\n",
    "            MLPMixer(num_tokens=self.num_tokens, num_channels=self.num_channels,\n",
    "                     token_dim_expansion_factor=self.token_dim_expansion_factor,\n",
    "                     channel_dim_expansion_factor=self.channel_dim_expansion_factor, dropout=self.dropout)\n",
    "            for _ in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=self.num_channels + self.node_feat_dim, out_features=self.node_feat_dim, bias=True)\n",
    "\n",
    "    def compute_src_dst_node_temporal_embeddings(self, src_node_ids: np.ndarray, dst_node_ids: np.ndarray,\n",
    "                                                 node_interact_times: np.ndarray, num_neighbors: int = 20, time_gap: int = 2000):\n",
    "        \"\"\"\n",
    "        compute source and destination node temporal embeddings\n",
    "        \n",
    "        :param src_node_ids: ndarray, shape (batch_size, )\n",
    "        :param dst_node_ids: ndarray, shape (batch_size, )\n",
    "        :param node_interact_times: ndarray, shape (batch_size, )\n",
    "        :param num_neighbors: int, number of neighbors to sample for each node\n",
    "        :param time_gap: int, time gap for neighbors to compute node features\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Tensor, shape (batch_size, node_feat_dim)\n",
    "        src_node_embeddings = self.compute_node_temporal_embeddings(node_ids=src_node_ids, node_interact_times=node_interact_times,\n",
    "                                                                    num_neighbors=num_neighbors, time_gap=time_gap)\n",
    "        # Tensor, shape (batch_size, node_feat_dim)\n",
    "        dst_node_embeddings = self.compute_node_temporal_embeddings(node_ids=dst_node_ids, node_interact_times=node_interact_times,\n",
    "                                                                    num_neighbors=num_neighbors, time_gap=time_gap)\n",
    "\n",
    "        return src_node_embeddings, dst_node_embeddings\n",
    "\n",
    "    def compute_node_temporal_embeddings(self, node_ids: np.ndarray, node_interact_times: np.ndarray,\n",
    "                                         num_neighbors: int = 20, time_gap: int = 2000):\n",
    "        \"\"\"\n",
    "        given node ids node_ids, and the corresponding time node_interact_times, return the temporal embeddings of nodes in node_ids\n",
    "\n",
    "        :param node_ids: ndarray, shape (batch_size, ), node ids\n",
    "        :param node_interact_times: ndarray, shape (batch_size, ), node interaction times\n",
    "        :param num_neighbors: int, number of neighbors to sample for each node\n",
    "        :param time_gap: int, time gap for neighbors to compute node features\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # link encoder\n",
    "        # get temporal neighbors, including neighbor ids, edge ids and time information\n",
    "        # neighbor_node_ids, ndarray, shape (batch_size, num_neighbors)\n",
    "        # neighbor_edge_ids, ndarray, shape (batch_size, num_neighbors)\n",
    "        # neighbor_times, ndarray, shape (batch_size, num_neighbors)\n",
    "        neighbor_node_ids, neighbor_edge_ids, neighbor_times = \\\n",
    "            self.neighbor_sampler.get_historical_neighbors(node_ids=node_ids,\n",
    "                                                           node_interact_times=node_interact_times,\n",
    "                                                           num_neighbors=num_neighbors)\n",
    "\n",
    "        # Tensor, shape (batch_size, num_neighbors, edge_feat_dim)\n",
    "        nodes_edge_raw_features = self.edge_raw_features[torch.from_numpy(neighbor_edge_ids)]\n",
    "        # Tensor, shape (batch_size, num_neighbors, time_feat_dim)\n",
    "        nodes_neighbor_time_features = self.time_encoder(timestamps=torch.from_numpy(node_interact_times[:, np.newaxis] - neighbor_times).float().to(self.device))\n",
    "\n",
    "        # ndarray, set the time features to all zeros for the padded timestamp\n",
    "        nodes_neighbor_time_features[torch.from_numpy(neighbor_node_ids == 0)] = 0.0\n",
    "\n",
    "        # Tensor, shape (batch_size, num_neighbors, edge_feat_dim + time_feat_dim)\n",
    "        combined_features = torch.cat([nodes_edge_raw_features, nodes_neighbor_time_features], dim=-1)\n",
    "        # Tensor, shape (batch_size, num_neighbors, num_channels)\n",
    "        combined_features = self.projection_layer(combined_features)\n",
    "\n",
    "        for mlp_mixer in self.mlp_mixers:\n",
    "            # Tensor, shape (batch_size, num_neighbors, num_channels)\n",
    "            combined_features = mlp_mixer(input_tensor=combined_features)\n",
    "\n",
    "        # Tensor, shape (batch_size, num_channels)\n",
    "        combined_features = torch.mean(combined_features, dim=1)\n",
    "\n",
    "        # node encoder\n",
    "        # get temporal neighbors of nodes, including neighbor ids\n",
    "        # time_gap_neighbor_node_ids, ndarray, shape (batch_size, time_gap)\n",
    "        time_gap_neighbor_node_ids, _, _ = self.neighbor_sampler.get_historical_neighbors(node_ids=node_ids,\n",
    "                                                                                          node_interact_times=node_interact_times,\n",
    "                                                                                          num_neighbors=time_gap)\n",
    "\n",
    "        # Tensor, shape (batch_size, time_gap, node_feat_dim)\n",
    "        nodes_time_gap_neighbor_node_raw_features = self.node_raw_features[torch.from_numpy(time_gap_neighbor_node_ids)]\n",
    "\n",
    "        # Tensor, shape (batch_size, time_gap)\n",
    "        valid_time_gap_neighbor_node_ids_mask = torch.from_numpy((time_gap_neighbor_node_ids > 0).astype(np.float32))\n",
    "        # note that if a node has no valid neighbor (whose valid_time_gap_neighbor_node_ids_mask are all zero), directly set the mask to -np.inf will make the\n",
    "        # scores after softmax be nan. Therefore, we choose a very large negative number (-1e10) instead of -np.inf to tackle this case\n",
    "        # Tensor, shape (batch_size, time_gap)\n",
    "        valid_time_gap_neighbor_node_ids_mask[valid_time_gap_neighbor_node_ids_mask == 0] = -1e10\n",
    "        # Tensor, shape (batch_size, time_gap)\n",
    "        scores = torch.softmax(valid_time_gap_neighbor_node_ids_mask, dim=1).to(self.device)\n",
    "\n",
    "        # Tensor, shape (batch_size, node_feat_dim), average over the time_gap neighbors\n",
    "        nodes_time_gap_neighbor_node_agg_features = torch.mean(nodes_time_gap_neighbor_node_raw_features * scores.unsqueeze(dim=-1), dim=1)\n",
    "\n",
    "        # Tensor, shape (batch_size, node_feat_dim), add features of nodes in node_ids\n",
    "        output_node_features = nodes_time_gap_neighbor_node_agg_features + self.node_raw_features[torch.from_numpy(node_ids)]\n",
    "\n",
    "        # Tensor, shape (batch_size, node_feat_dim)\n",
    "        node_embeddings = self.output_layer(torch.cat([combined_features, output_node_features], dim=1))\n",
    "\n",
    "        return node_embeddings\n",
    "\n",
    "    def set_neighbor_sampler(self, neighbor_sampler: NeighborSampler):\n",
    "        \"\"\"\n",
    "        set neighbor sampler to neighbor_sampler and reset the random state (for reproducing the results for uniform and time_interval_aware sampling)\n",
    "\n",
    "        :param neighbor_sampler: NeighborSampler, neighbor sampler\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.neighbor_sampler = neighbor_sampler\n",
    "        assert self.neighbor_sampler.seed is not None\n",
    "        self.neighbor_sampler.reset_random_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a7b06a",
   "metadata": {},
   "source": [
    "### 6C. Implementing GraphMixer's link encoder MLP (Question 7: 10 points)\n",
    "\n",
    "Follow the below schematic to implement the `ffn` module representing the feed-fordward net. For an input $\\mathbf{x}$ of shape `(*, input_dim)`,\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = \\operatorname{GELU}(\\operatorname{Linear}(\\mathbf{x}))\n",
    "$$\n",
    "$$\n",
    "\\mathbf{a} = \\operatorname{Dropout}(\\mathbf{z})\n",
    "$$\n",
    "$$\n",
    "\\mathbf{y} = \\operatorname{Dropout}(\\operatorname{Linear}(\\mathbf{a}))\n",
    "$$\n",
    "\n",
    "**NOTE:** Ensure the dimensions match for the `Linear` layers. The MLP expands the input by some expansion factor and brings it back to the original input dimension. You can either create this with separate layers or can bunch them together using `nn.Sequential(...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int, dim_expansion_factor: float, dropout: float = 0.0):\n",
    "        \"\"\"\n",
    "        two-layered MLP with GELU activation function.\n",
    "        :param input_dim: int, dimension of input\n",
    "        :param dim_expansion_factor: float, dimension expansion factor\n",
    "        :param dropout: float, dropout rate\n",
    "        \"\"\"\n",
    "        super(FeedForwardNet, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.dim_expansion_factor = dim_expansion_factor\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        ## Question 7: Implement the feed-forward network used in MLPMixer\n",
    "        ############# Your code here ############\n",
    "        ## (~4-6 lines of code)\n",
    "        \n",
    "        self.ffn = None\n",
    "        \n",
    "        #########################################\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        feed forward net forward process\n",
    "        :param x: Tensor, shape (*, input_dim)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.ffn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1cd1be",
   "metadata": {},
   "source": [
    "### 6D. Implmenting the MLPMixer (Question 8: 10 points)\n",
    "\n",
    "The core of our GraphMixer relies on MLPMixer which you'll be implementing below. Carefully follow the equations below while constructing the `forward(...)` method in the `MLPMixer` object. The layer takes in an input tensor $\\mathbf{H}_{\\text{input}}$ of shape `(batch_Size, num_tokens, num_channels)` and outputs a tensor of shape `(batch_size, num_tokens, num_channels)` after \"mixing\" the channel information (hence, the name)!\n",
    "\n",
    "$$\n",
    "\\mathbf{H}_{\\text{token}} = \\operatorname{FFN}(\\mathbf{H}_{\\text{input}})\n",
    "$$\n",
    "$$\n",
    "\\operatorname{mix-tokens-and-channels}(\\mathbf{H}_{\\text{token}})\n",
    "$$\n",
    "$$\n",
    "\\mathbf{H}_{\\text{token}}^{\\prime} = \\mathbf{H}_{\\text{token}} + \\mathbf{H}_{\\text{input}}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{H}_{\\text{channel}} = \\operatorname{FFN}(\\mathbf{H}_{\\text{token}}^{\\prime})\n",
    "$$\n",
    "$$\n",
    "\\mathbf{H}_{\\text{output}} = \\mathbf{H}_{\\text{channel}} + \\mathbf{H}_{\\text{token}}^{\\prime}\n",
    "$$\n",
    "\n",
    "\n",
    "Remember, in PyTorch, you can permute (swap) the dimensions of a tensor using `.permute(...)` and state the indices you want swapped. For example, to transpose a matrix `a`, you can use `a.permute(1, 0)` that swaps the first and second dimensions. You can do this for any dimensions by keying in the dimensions to be swapped.\n",
    "\n",
    "Make sure to use the `FeedForwardNet` module you've implemented above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3391016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPMixer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            num_tokens: int, \n",
    "            num_channels: int, \n",
    "            token_dim_expansion_factor: float = 0.5,\n",
    "            channel_dim_expansion_factor: float = 4.0, \n",
    "            dropout: float = 0.0\n",
    "        ):\n",
    "        \"\"\"\n",
    "        MLP Mixer.\n",
    "        \n",
    "        :param num_tokens: int, number of tokens\n",
    "        :param num_channels: int, number of channels\n",
    "        :param token_dim_expansion_factor: float, dimension expansion factor for tokens\n",
    "        :param channel_dim_expansion_factor: float, dimension expansion factor for channels\n",
    "        :param dropout: float, dropout rate\n",
    "        \"\"\"\n",
    "        super(MLPMixer, self).__init__()\n",
    "\n",
    "        self.token_norm = nn.LayerNorm(num_tokens)\n",
    "        self.token_feedforward = FeedForwardNet(input_dim=num_tokens, dim_expansion_factor=token_dim_expansion_factor,\n",
    "                                                dropout=dropout)\n",
    "\n",
    "        self.channel_norm = nn.LayerNorm(num_channels)\n",
    "        self.channel_feedforward = FeedForwardNet(input_dim=num_channels, dim_expansion_factor=channel_dim_expansion_factor,\n",
    "                                                  dropout=dropout)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor):\n",
    "        \"\"\"\n",
    "        mlp mixer to compute over tokens and channels\n",
    "        \n",
    "        :param input_tensor: Tensor, shape (batch_size, num_tokens, num_channels)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # swap tokens and channels\n",
    "        input_tensor = input_tensor.permute(0, 2, 1)\n",
    "        \n",
    "        ## Question 8: Implement the MLPMixer forward pass that mixes tokens and channels\n",
    "        ############# Your code here ############\n",
    "        ## (~5-6 lines of code)\n",
    "        \n",
    "        #########################################\n",
    "\n",
    "        return output_tensor # Tensor of shape (batch_size, num_tokens, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697484ad-17df-41ac-bb15-0d9e71064c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dynamic_backbone = GraphMixer(\n",
    "                        node_raw_features=entity_embeddings, \n",
    "                        edge_raw_features=rel_embeddings, \n",
    "                        neighbor_sampler=train_neighbor_sampler,\n",
    "                        time_feat_dim=100, \n",
    "                        num_tokens=30, \n",
    "                        num_layers=2, \n",
    "                        dropout=0.2, \n",
    "                        device=device\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26277af9-1015-4f9a-882d-5123db610cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_classifier = MLPClassifier_edge(input_dim=entity_embeddings.shape[1], dropout=0.1, cat_num=cat_num)\n",
    "\n",
    "model = nn.Sequential(dynamic_backbone, edge_classifier).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc61bf-ad97-4443-aa34-b0a92eb5290e",
   "metadata": {},
   "source": [
    "## 7. Training\n",
    "\n",
    "We'll now initialize the GraphMixer model and train it on our preprocessed temporal knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76343b06-816c-42e2-bc25-cb041d414c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=5e-4)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9df41",
   "metadata": {},
   "source": [
    "Notice above that our `model` module has two parts: `model[0]` referring to the backbone and `model[1]` referring to the edge classifier. We'll be accessing these separate parts as and when necessary hereon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ef673-fbf5-4090-a70c-919f50aa99ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].set_neighbor_sampler(train_neighbor_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d270f3eb",
   "metadata": {},
   "source": [
    "### Question 9-10 (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499a221-c03a-4b8b-b642-bd23ea09f43b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    \n",
    "    # store train losses and metrics\n",
    "    train_total_loss, train_y_trues, train_y_predicts = 0.0, [], []\n",
    "    train_idx_data_loader_tqdm = tqdm(train_idx_data_loader, ncols=120, desc=f\"epoch:{epoch}\")\n",
    "    \n",
    "    for batch_idx, train_data_indices in enumerate(train_idx_data_loader_tqdm):\n",
    "        train_data_indices = train_data_indices.numpy()\n",
    "        batch_src_node_ids, batch_dst_node_ids, batch_node_interact_times, batch_edge_ids, batch_labels = \\\n",
    "            train_data.src_node_ids[train_data_indices], train_data.dst_node_ids[train_data_indices], \\\n",
    "            train_data.node_interact_times[train_data_indices], train_data.edge_ids[train_data_indices], train_data.labels[train_data_indices]\n",
    "        \n",
    "        \"\"\"\n",
    "        We need to compute for positive and negative edges respectively, because the new sampling strategy \n",
    "        (for evaluation) allows the negative source nodes to be different from the source nodes. \n",
    "        \n",
    "        This is different from previous works that just replace destination nodes with negative destination nodes\n",
    "        get temporal embedding of source and destination nodes.\n",
    "        \n",
    "        You'll then have two Tensors both with shape (batch_size, node_feat_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Question 9: Get the temporal embeddings for src and dest nodes using the backbone model's \n",
    "        ##            `compute_src_dst_node_temporal_embeddings` method. Use a time gap of 2000 and number of neighbors 30\n",
    "        ############# Your code here ############\n",
    "        ## (~1-2 lines of code)\n",
    "        \n",
    "        batch_src_node_embeddings, batch_dst_node_embeddings = None\n",
    "        \n",
    "        #########################################\n",
    "        \n",
    "        \n",
    "        ## Question 10: Get the predicted probabilities from the Edge Classifier MLP\n",
    "        ############# Your code here ############\n",
    "        ## (~1-2 lines of code)\n",
    "        ## Use `model[1]` and pass in the src and dest temporal node embeddings, as well as the raw edge features from the backbone\n",
    "\n",
    "        # get predicted probabilities, shape (batch_size, )\n",
    "        predicts = None\n",
    "        \n",
    "        #########################################\n",
    "        \n",
    "        pred_labels = torch.max(predicts, dim=1)[1]\n",
    "        labels = torch.from_numpy(batch_labels).long().to(predicts.device)\n",
    "        loss = loss_func(predicts, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_total_loss += loss.item()\n",
    "\n",
    "    print(\"avg loss\", train_total_loss / len(train_idx_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec2ad3",
   "metadata": {},
   "source": [
    "### 8. Evaluation\n",
    "\n",
    "We'll first write some helper functions to evaluate our model. This includes precision, recall, and F1-score. We'll use `scikit-learn`'s inbuilt functions for this. You can read the documentation [here](https://scikit-learn.org/0.15/modules/generated/sklearn.metrics.precision_score.html) if in doubt on how to invoke these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6717cfc",
   "metadata": {},
   "source": [
    "### Question 11 (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e823f9-b063-4d99-ab82-6b364dc7c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "def calculate_metrics(predicts: torch.Tensor, labels: torch.Tensor):\n",
    "    \"\"\"\n",
    "    get metrics for the edge classification task\n",
    "    \n",
    "    :param predicts: Tensor, shape (num_samples, )\n",
    "    :param labels: Tensor, shape (num_samples, )\n",
    "    :return:\n",
    "        dictionary of metrics {'metric_name_1': metric_1, ...}\n",
    "    \"\"\"\n",
    "    \n",
    "    predicts = predicts.cpu().detach().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    \n",
    "    ## Question 11: Implement macro, micro, and weighted metrics for precision, recall, and F1-score\n",
    "    ############# Your code here ############\n",
    "    ## (9 lines of code)\n",
    "    \n",
    "    P_macro = None\n",
    "    R_macro = None\n",
    "    F_macro = None\n",
    "\n",
    "    P_micro = None\n",
    "    R_micro = None\n",
    "    F_micro = None\n",
    "\n",
    "    P_weight = None\n",
    "    R_weight = None\n",
    "    F_weight = None\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return {\n",
    "            'p_macro': P_macro, \n",
    "            'R_macro': R_macro, \n",
    "            'F_macro': F_macro, \n",
    "            'p_micro': P_micro, \n",
    "            'R_micro': R_micro, \n",
    "            'F_micro': F_micro, \n",
    "            'p_weighted': P_weight, \n",
    "            'R_weighted': R_weight, \n",
    "            'F_weighted': F_weight\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b593c",
   "metadata": {},
   "source": [
    "### 8A. Evaluating on validation data (Question 12-13: 10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e1878-8c36-4a92-9571-ee7aadbb20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].set_neighbor_sampler(full_neighbor_sampler)\n",
    "\n",
    "def evaluate(model, evaluate_data, idx_dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # store evaluate losses, trues and predicts\n",
    "        evaluate_total_loss, evaluate_y_trues, evaluate_y_predicts = 0.0, [], []\n",
    "        evaluate_idx_data_loader_tqdm = tqdm(idx_dataloader, ncols=120)\n",
    "        \n",
    "        for batch_idx, evaluate_data_indices in enumerate(evaluate_idx_data_loader_tqdm):\n",
    "            evaluate_data_indices = evaluate_data_indices.numpy()\n",
    "            batch_src_node_ids, batch_dst_node_ids, batch_node_interact_times, batch_edge_ids, batch_labels = \\\n",
    "                evaluate_data.src_node_ids[evaluate_data_indices], evaluate_data.dst_node_ids[evaluate_data_indices], \\\n",
    "                evaluate_data.node_interact_times[evaluate_data_indices], evaluate_data.edge_ids[evaluate_data_indices], \\\n",
    "                evaluate_data.labels[evaluate_data_indices]\n",
    "            \n",
    "            # get temporal embedding of source and destination nodes\n",
    "            # two Tensors, with shape (batch_size, node_feat_dim)\n",
    "            \n",
    "            ## Question 12: Get the temporal embeddings for src and dest nodes using the backbone model's \n",
    "            ##            `compute_src_dst_node_temporal_embeddings` method. Use a time gap of 2000 and number of neighbors 30\n",
    "            ############# Your code here ############\n",
    "            ## (~1-2 lines of code)\n",
    "            ## You already did this for Question 9\n",
    "\n",
    "            batch_src_node_embeddings, batch_dst_node_embeddings = None\n",
    "\n",
    "            #########################################\n",
    "            \n",
    "            \n",
    "            ## Question 13: Get the predicted probabilities from the Edge Classifier MLP\n",
    "            ############# Your code here ############\n",
    "            ## (~1-2 lines of code)\n",
    "            ## Use `model[1]` and pass in the src and dest temporal node embeddings, as well as the raw edge features from the backbone\n",
    "            ## You already did this for Question 10\n",
    "\n",
    "            # get predicted probabilities, shape (batch_size, )\n",
    "            predicts = None\n",
    "\n",
    "            #########################################\n",
    "            \n",
    "            pred_labels = torch.max(predicts, dim=1)[1]\n",
    "            labels = torch.from_numpy(batch_labels).int().type(torch.LongTensor).to(predicts.device)\n",
    "\n",
    "            loss = loss_func(input=predicts, target=labels)\n",
    "            evaluate_total_loss += loss.item()\n",
    "            \n",
    "            evaluate_y_trues.append(labels)\n",
    "            evaluate_y_predicts.append(pred_labels)\n",
    "            evaluate_idx_data_loader_tqdm.set_description(f'evaluate for the {batch_idx + 1}-th batch, evaluate loss: {loss.item()}')\n",
    "        \n",
    "        evaluate_total_loss /= (batch_idx + 1)\n",
    "        evaluate_y_trues = torch.cat(evaluate_y_trues, dim=0)\n",
    "        evaluate_y_predicts = torch.cat(evaluate_y_predicts, dim=0)\n",
    "        \n",
    "        return calculate_metrics(predicts=evaluate_y_predicts, labels=evaluate_y_trues)\n",
    "\n",
    "evaluate(model, val_data, val_idx_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019fb11",
   "metadata": {},
   "source": [
    "### 8B. Evaluating on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ac0d8-367d-4096-843c-e142f0eedaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_data, test_idx_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5423c5",
   "metadata": {},
   "source": [
    "We've only trained this model for 5 epochs here. If you have a larger compute budget, feel free to see if you can improve the model's test/val performance even more! Other tricks might include better neighbor samplers. Ultimately, for such large-scale graph learning tasks, miscellaneous optimizations must be made to ensure compute efficiency.\n",
    "\n",
    "> This is the FINAL notebook-based assignment for this term. Hope you've enjoyed the coding exercises we arranged for you. \n",
    "> \n",
    "> If you like what you learned, consider joining Rex Ying's [Graph and Geometric Learning Lab](https://graph-and-geometric-learning.github.io/)!! We'd be thrilled to have you :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
